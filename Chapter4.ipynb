{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "Find out more about sequence objects using Python's help facility. In the interpreter, type help(str), help(list), and help(tuple). This will give you a full list of the functions supported by each type. Some functions have special names flanked with underscore; as the help documentation shows, each such function corresponds to something more familiar. For example x.__getitem__(y) is just a long-winded way of saying x[y]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class str in module builtins:\n",
      "\n",
      "class str(object)\n",
      " |  str(object='') -> str\n",
      " |  str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
      " |  \n",
      " |  Create a new string object from the given object. If encoding or\n",
      " |  errors is specified, then the object must expose a data buffer\n",
      " |  that will be decoded using the given encoding and error handler.\n",
      " |  Otherwise, returns the result of object.__str__() (if defined)\n",
      " |  or repr(object).\n",
      " |  encoding defaults to sys.getdefaultencoding().\n",
      " |  errors defaults to 'strict'.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __format__(self, format_spec, /)\n",
      " |      Return a formatted version of the string as described by format_spec.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __sizeof__(self, /)\n",
      " |      Return the size of the string in memory, in bytes.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  capitalize(self, /)\n",
      " |      Return a capitalized version of the string.\n",
      " |      \n",
      " |      More specifically, make the first character have upper case and the rest lower\n",
      " |      case.\n",
      " |  \n",
      " |  casefold(self, /)\n",
      " |      Return a version of the string suitable for caseless comparisons.\n",
      " |  \n",
      " |  center(self, width, fillchar=' ', /)\n",
      " |      Return a centered string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  count(...)\n",
      " |      S.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of substring sub in\n",
      " |      string S[start:end].  Optional arguments start and end are\n",
      " |      interpreted as in slice notation.\n",
      " |  \n",
      " |  encode(self, /, encoding='utf-8', errors='strict')\n",
      " |      Encode the string using the codec registered for encoding.\n",
      " |      \n",
      " |      encoding\n",
      " |        The encoding in which to encode the string.\n",
      " |      errors\n",
      " |        The error handling scheme to use for encoding errors.\n",
      " |        The default is 'strict' meaning that encoding errors raise a\n",
      " |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and\n",
      " |        'xmlcharrefreplace' as well as any other name registered with\n",
      " |        codecs.register_error that can handle UnicodeEncodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      S.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      suffix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  expandtabs(self, /, tabsize=8)\n",
      " |      Return a copy where all tab characters are expanded using spaces.\n",
      " |      \n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      S.find(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  format(...)\n",
      " |      S.format(*args, **kwargs) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  format_map(...)\n",
      " |      S.format_map(mapping) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from mapping.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  index(...)\n",
      " |      S.index(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found, \n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  isalnum(self, /)\n",
      " |      Return True if the string is an alpha-numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is alpha-numeric if all characters in the string are alpha-numeric and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isalpha(self, /)\n",
      " |      Return True if the string is an alphabetic string, False otherwise.\n",
      " |      \n",
      " |      A string is alphabetic if all characters in the string are alphabetic and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isascii(self, /)\n",
      " |      Return True if all characters in the string are ASCII, False otherwise.\n",
      " |      \n",
      " |      ASCII characters have code points in the range U+0000-U+007F.\n",
      " |      Empty string is ASCII too.\n",
      " |  \n",
      " |  isdecimal(self, /)\n",
      " |      Return True if the string is a decimal string, False otherwise.\n",
      " |      \n",
      " |      A string is a decimal string if all characters in the string are decimal and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isdigit(self, /)\n",
      " |      Return True if the string is a digit string, False otherwise.\n",
      " |      \n",
      " |      A string is a digit string if all characters in the string are digits and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isidentifier(self, /)\n",
      " |      Return True if the string is a valid Python identifier, False otherwise.\n",
      " |      \n",
      " |      Use keyword.iskeyword() to test for reserved identifiers such as \"def\" and\n",
      " |      \"class\".\n",
      " |  \n",
      " |  islower(self, /)\n",
      " |      Return True if the string is a lowercase string, False otherwise.\n",
      " |      \n",
      " |      A string is lowercase if all cased characters in the string are lowercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  isnumeric(self, /)\n",
      " |      Return True if the string is a numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is numeric if all characters in the string are numeric and there is at\n",
      " |      least one character in the string.\n",
      " |  \n",
      " |  isprintable(self, /)\n",
      " |      Return True if the string is printable, False otherwise.\n",
      " |      \n",
      " |      A string is printable if all of its characters are considered printable in\n",
      " |      repr() or if it is empty.\n",
      " |  \n",
      " |  isspace(self, /)\n",
      " |      Return True if the string is a whitespace string, False otherwise.\n",
      " |      \n",
      " |      A string is whitespace if all characters in the string are whitespace and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  istitle(self, /)\n",
      " |      Return True if the string is a title-cased string, False otherwise.\n",
      " |      \n",
      " |      In a title-cased string, upper- and title-case characters may only\n",
      " |      follow uncased characters and lowercase characters only cased ones.\n",
      " |  \n",
      " |  isupper(self, /)\n",
      " |      Return True if the string is an uppercase string, False otherwise.\n",
      " |      \n",
      " |      A string is uppercase if all cased characters in the string are uppercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  join(self, iterable, /)\n",
      " |      Concatenate any number of strings.\n",
      " |      \n",
      " |      The string whose method is called is inserted in between each given string.\n",
      " |      The result is returned as a new string.\n",
      " |      \n",
      " |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
      " |  \n",
      " |  ljust(self, width, fillchar=' ', /)\n",
      " |      Return a left-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  lower(self, /)\n",
      " |      Return a copy of the string converted to lowercase.\n",
      " |  \n",
      " |  lstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  partition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string.  If the separator is found,\n",
      " |      returns a 3-tuple containing the part before the separator, the separator\n",
      " |      itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing the original string\n",
      " |      and two empty strings.\n",
      " |  \n",
      " |  replace(self, old, new, count=-1, /)\n",
      " |      Return a copy with all occurrences of substring old replaced by new.\n",
      " |      \n",
      " |        count\n",
      " |          Maximum number of occurrences to replace.\n",
      " |          -1 (the default value) means replace all occurrences.\n",
      " |      \n",
      " |      If the optional argument count is given, only the first count occurrences are\n",
      " |      replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      S.rfind(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      S.rindex(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  rjust(self, width, fillchar=' ', /)\n",
      " |      Return a right-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  rpartition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string, starting at the end. If\n",
      " |      the separator is found, returns a 3-tuple containing the part before the\n",
      " |      separator, the separator itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing two empty strings\n",
      " |      and the original string.\n",
      " |  \n",
      " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the words in the string, using sep as the delimiter string.\n",
      " |      \n",
      " |        sep\n",
      " |          The delimiter according which to split the string.\n",
      " |          None (the default value) means split according to any whitespace,\n",
      " |          and discard empty strings from the result.\n",
      " |        maxsplit\n",
      " |          Maximum number of splits to do.\n",
      " |          -1 (the default value) means no limit.\n",
      " |      \n",
      " |      Splits are done starting at the end of the string and working to the front.\n",
      " |  \n",
      " |  rstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with trailing whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  split(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the words in the string, using sep as the delimiter string.\n",
      " |      \n",
      " |      sep\n",
      " |        The delimiter according which to split the string.\n",
      " |        None (the default value) means split according to any whitespace,\n",
      " |        and discard empty strings from the result.\n",
      " |      maxsplit\n",
      " |        Maximum number of splits to do.\n",
      " |        -1 (the default value) means no limit.\n",
      " |  \n",
      " |  splitlines(self, /, keepends=False)\n",
      " |      Return a list of the lines in the string, breaking at line boundaries.\n",
      " |      \n",
      " |      Line breaks are not included in the resulting list unless keepends is given and\n",
      " |      true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      S.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      prefix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  strip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading and trailing whitespace remove.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  swapcase(self, /)\n",
      " |      Convert uppercase characters to lowercase and lowercase characters to uppercase.\n",
      " |  \n",
      " |  title(self, /)\n",
      " |      Return a version of the string where each word is titlecased.\n",
      " |      \n",
      " |      More specifically, words start with uppercased characters and all remaining\n",
      " |      cased characters have lower case.\n",
      " |  \n",
      " |  translate(self, table, /)\n",
      " |      Replace each character in the string using the given translation table.\n",
      " |      \n",
      " |        table\n",
      " |          Translation table, which must be a mapping of Unicode ordinals to\n",
      " |          Unicode ordinals, strings, or None.\n",
      " |      \n",
      " |      The table must implement lookup/indexing via __getitem__, for instance a\n",
      " |      dictionary or list.  If this operation raises LookupError, the character is\n",
      " |      left untouched.  Characters mapped to None are deleted.\n",
      " |  \n",
      " |  upper(self, /)\n",
      " |      Return a copy of the string converted to uppercase.\n",
      " |  \n",
      " |  zfill(self, width, /)\n",
      " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      " |      \n",
      " |      The string is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  maketrans(x, y=None, z=None, /)\n",
      " |      Return a translation table usable for str.translate().\n",
      " |      \n",
      " |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      " |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      " |      Character keys will be then converted to ordinals.\n",
      " |      If there are two arguments, they must be strings of equal length, and\n",
      " |      in the resulting dictionary, each character in x will be mapped to the\n",
      " |      character at the same position in y. If there is a third argument, it\n",
      " |      must be a string, whose characters will be mapped to None in the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "Identify three operations that can be performed on both tuples and lists. Identify three list operations that cannot be performed on tuples. Name a context where using a list instead of a tuple generates a Python error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=(3,4,4)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2=(4,5)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 4, 4, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1+t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    }
   ],
   "source": [
    "print(t1.count(3),t1.index(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tuple+lists - count,index,concatenation\n",
    "* lists - append,sort,pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "Find out how to create a tuple consisting of a single item. There are at least two ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) (2,) (1,)\n"
     ]
    }
   ],
   "source": [
    "t1=3,\n",
    "t2=(2,)\n",
    "t3=tuple([1])\n",
    "print(t1,t2,t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "Create a list words = ['is', 'NLP', 'fun', '?']. Use a series of assignment statements (e.g. words[1] = words[2]) and a temporary variable tmp to transform this list into the list ['NLP', 'is', 'fun', '!']. Now do the same transformation using tuple assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'NLP', 'fun', '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['is', 'NLP', 'fun', '?']\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp=words[0]\n",
    "words[0]=words[1]\n",
    "words[1]=tmp\n",
    "words[3]='!'\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'is', 'fun', '!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['is', 'NLP', 'fun', '?']\n",
    "words[0],words[1],words[3]=words[1],words[0],'!'\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5\n",
    "Read about the built-in comparison function cmp, by typing help(cmp). How does it differ in behavior from the comparison operators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cmp is not available in latest python version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6\n",
    "Does the method for creating a sliding window of n-grams behave correctly for the two limiting cases: n = 1, and n = len(sent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave'],\n",
       " ['dog', 'gave', 'John'],\n",
       " ['gave', 'John', 'the'],\n",
       " ['John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 3\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The'], ['dog'], ['gave'], ['John'], ['the'], ['newspaper']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(sent)\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Behaved correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7\n",
    " We pointed out that when empty strings and empty lists occur in the condition part of an if clause, they evaluate to False. In this case, they are said to be occurring in a Boolean context. Experiment with different kind of non-Boolean expressions in Boolean contexts, and see whether they evaluate as True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if []:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '':\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if [1]:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "while []:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8\n",
    "Use the inequality operators to compare strings, e.g. 'Monty' < 'Python'. What happens when you do 'Z' < 'a'? Try pairs of strings which have a common prefix, e.g.  'Monty' < 'Montague'. Read up on \"lexicographical sort\" in order to understand what is going on here. Try comparing structured objects, e.g. ('Monty', 1) < ('Monty', 2). Does this behave as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty'<'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Z'<'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty'<'Montague'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('Monty',1)<('Monty',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tuples and lists are compared lexicographically using comparison of corresponding elements. This means that to compare equal, each element must compare equal and the two sequences must be of the same type and have the same length.\n",
    "\n",
    "* If not equal, the sequences are ordered the same as their first differing elements. For example, cmp([1,2,x], [1,2,y]) returns the same as cmp(x,y). If the corresponding element does not exist, the shorter sequence is considered smaller (for example, [1,2] < [1,2,3] returns True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0,1)<(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0,1)<(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,1)<(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,2)<(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,2)<(1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9\n",
    "Write code that removes whitespace at the beginning and end of a string, and normalizes whitespace between words to be a single space character.<br>\n",
    "\n",
    "* do this task using split() and join()\n",
    "* do this task using regular expression substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nan', 'dini']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=' nan  dini '\n",
    "s=s.split()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nan dini'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=' '.join(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nan dini'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=' nan  dini '\n",
    "import re\n",
    "s=re.sub('^\\s|\\s$','',s)\n",
    "s=re.sub('\\s+',' ',s)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 10\n",
    "Write a program to sort words by length. Define a helper function cmp_len which uses the cmp comparison function on word lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp_len(words):\n",
    "    words.sort(key=lambda x:len(x))\n",
    "    return words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'ab']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_len(['a','ab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'ab']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_len(['ab','a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 11\n",
    "Create a list of words and store it in a variable sent1. Now assign sent2 = sent1. Modify one of the items in sent1 and verify that sent2 has changed. <br>\n",
    "\n",
    "* Now try the same exercise but instead assign sent2 = sent1[:]. Modify sent1 again and see what happens to sent2. Explain.<br>\n",
    "* Now define text1 to be a list of lists of strings (e.g. to represent a text consisting of multiple sentences. Now assign text2 = text1[:], assign a new value to one of the words, e.g. text1[1][1] = 'Monty'. Check what this did to text2. Explain.<br>\n",
    "* Load Python's deepcopy() function (i.e. from copy import deepcopy), consult its documentation, and test that it makes a fresh copy of any object.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'gave', 'John', 'the', 'newspaper'] ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n"
     ]
    }
   ],
   "source": [
    "sent1=['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "sent2=sent1\n",
    "print(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'dog', 'gave', 'John', 'the', 'newspaper'] ['A', 'dog', 'gave', 'John', 'the', 'newspaper']\n"
     ]
    }
   ],
   "source": [
    "sent1[0]='A'\n",
    "print(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'gave', 'John', 'the', 'newspaper'] ['A', 'dog', 'gave', 'John', 'the', 'newspaper']\n"
     ]
    }
   ],
   "source": [
    "sent2=sent1[:]\n",
    "sent1[0]='The'\n",
    "print(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'],\n",
       " ['A', 'dog', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=[['The', 'dog', 'gave', 'John', 'the', 'newspaper'],['A', 'dog', 'gave', 'John', 'the', 'newspaper']]\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'],\n",
       " ['A', 'dog', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2=text1[:]\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'],\n",
       " ['A', 'Monty', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[1][1]='Monty'\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'],\n",
       " ['A', 'Monty', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't copy inner lists but referenced them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'],\n",
       " ['A', 'dog', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "text2=deepcopy(text1)\n",
    "text1[1][1]='dog'\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'],\n",
       " ['A', 'Monty', 'gave', 'John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 12\n",
    "Initialize an n-by-m list of lists of empty strings using list multiplication, e.g. word_table = [[''] * n] * m. What happens when you set one of its values, e.g. word_table[1][2] = \"hello\"? Explain why this happens. Now write an expression using range() to construct a list of lists, and show that it does not have this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NLP', 'NLP', 'NLP'], ['NLP', 'NLP', 'NLP'], ['NLP', 'NLP', 'NLP']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table=[['NLP']*3]*3\n",
    "word_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table[1][2]='hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NLP', 'NLP', 'hello'], ['NLP', 'NLP', 'hello'], ['NLP', 'NLP', 'hello']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication creates copy of the same list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NLP', 'NLP', 'NLP'], ['NLP', 'NLP', 'hello'], ['NLP', 'NLP', 'NLP']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table = [['NLP' for count1 in range(3)] for count2 in range(3)]\n",
    "word_table[1][2] = \"hello\"\n",
    "word_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 13\n",
    "Write code to initialize a two-dimensional array of sets called word_vowels and process a list of words, adding each word to word_vowels[l][v] where l is the length of the word and v is the number of vowels it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog', 'the', 'The', 'cat'}\n",
      "{'newspaper'}\n"
     ]
    }
   ],
   "source": [
    "word_vowels = [[]]\n",
    "words = ['The', 'dog', 'gave', 'John', 'the', 'newspaper', 'The', 'cat', 'miowed']\n",
    "for word in words:\n",
    "    if (len(word) > len(word_vowels)-1):\n",
    "        for index in range(len(word_vowels), len(word)+1):\n",
    "            word_vowels.append([])\n",
    "    num_vowels = len(re.findall(r'[aeiouAEIOU]', word))\n",
    "    if (num_vowels > len(word_vowels[len(word)])-1):\n",
    "        for index in range(len(word_vowels[len(word)]), num_vowels+1):\n",
    "            word_vowels[len(word)].append(set())\n",
    "    word_vowels[len(word)][num_vowels].add(word)\n",
    "print(word_vowels[3][1])\n",
    "print(word_vowels[9][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 14\n",
    "Write a function novel10(text) that prints any word that appeared in the last 10% of a text that had not been encountered earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novel10(text):\n",
    "    i=round(0.9*len(text)+1);\n",
    "    train=text[:i]\n",
    "    test=text[i:];\n",
    "    print([word for word in test if word not in train]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nati', 'aga', 'His', 'Phallu', 'Hezron', 'Carmi', 'Jemuel', 'Jamin', 'Ohad', 'Jachin', 'Shaul', 'Canaanitish', 'Gershon', 'Kohath', 'Merari', 'Zar', 'Hezron', 'Hamul', 'Tola', 'Phuvah', 'Job', 'Shimron', 'Sered', 'Jahleel', 'Din', 'Ziphion', 'Haggi', 'Shuni', 'Ezbon', 'Eri', 'Arodi', 'Areli', 'Jimnah', 'Ishuah', 'Isui', 'Beriah', 'Serah', 'Beriah', 'Heber', 'Malchiel', 'sixteen', 'Belah', 'Becher', 'Ashbel', 'Gera', 'Naaman', 'Ehi', 'Rosh', 'Muppim', 'Huppim', 'Ard', 'Hushim', 'Jahzeel', 'Guni', 'Jezer', 'Shillem', 'direct', 'presented', 'shepherds', 'occupation', 'fathe', 'shepherd', 'presented', 'occupation', 'shepherds', 'morever', 'pasture', 'activity', 'rulers', 'pilgrimage', 'attained', 'pilgrimage', 'Rameses', 'nourished', 'boug', 'faileth', 'fail', 'exchange', 'horses', 'bodies', 'lan', 'desolate', 'priests', 'priests', 'assigned', 'sow', 'increase', 'parts', 'saved', 'priests', 'multiplied', 'nigh', 'bed', 'si', 'strengthened', 'bed', 'issue', 'begettest', 'Padan', 'guiding', 'wittingly', 'Angel', 'redeemed', 'lads', 'remove', 'Not', 'Manass', 'last', 'excellency', 'dignity', 'excellency', 'pow', 'Unstable', 'excel', 'wentest', 'bed', 'defiledst', 'couch', 'instruments', 'cruelty', 'secret', 'assembly', 'honour', 'unit', 'selfwill', 'wall', 'fierce', 'cru', 'lion', 'whelp', 'prey', 'stooped', 'couched', 'lion', 'lion', 'rouse', 'sceptre', 'lawgiver', 'Shiloh', 'Binding', 'foal', 'colt', 'His', 'teeth', 'haven', 'haven', 'ships', 'Zidon', 'strong', 'couching', 'burdens', 'tribute', 'tribes', 'adder', 'path', 'biteth', 'horse', 'heels', 'rider', 'waited', 'salvation', 'overcome', 'overcome', 'last', 'royal', 'dainties', 'hind', 'loose', 'giveth', 'bough', 'bough', 'run', 'wa', 'archers', 'sorely', 'arms', 'strong', 'shepherd', 'blessings', 'blessings', 'blessings', 'breasts', 'blessings', 'blessings', 'progenitors', 'utmost', 'hil', 'crown', 'ravin', 'wolf', 'devour', 'prey', 'spoil', 'tribes', 'peop', 'purchase', 'commanding', 'bed', 'yielded', 'physicians', 'embalm', 'physicians', 'embalmed', 'embalm', 'past', 'elders', 'elders', 'chariots', 'horsemen', 'threshingfloor', 'Atad', 'lamentati', 'floor', 'Atad', 'Egyptia', 'Abelmizraim', 'requite', 'messenger', 'Forgive', 'forgive', 'meant', 'Machir', 'visit', 'visit', 'embalmed', 'coffin']\n"
     ]
    }
   ],
   "source": [
    "novel10(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 15\n",
    "Write a program that takes a sentence expressed as a single string, splits it and counts up the words. Get it to print out each word and the word's frequency, one per line, in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWords(sent):\n",
    "    sent=sent.split();\n",
    "    count=len(sent);\n",
    "    sent.sort();\n",
    "    print(*[{w:sent.count(w)} for w in sent],sep='\\n');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You shall know the word by the company it keeps'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent='You shall know the word by the company it keeps'\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'You': 1}\n",
      "{'by': 1}\n",
      "{'company': 1}\n",
      "{'it': 1}\n",
      "{'keeps': 1}\n",
      "{'know': 1}\n",
      "{'shall': 1}\n",
      "{'the': 2}\n",
      "{'the': 2}\n",
      "{'word': 1}\n"
     ]
    }
   ],
   "source": [
    "countWords(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 16\n",
    "Read up on Gematria, a method for assigning numbers to words, and for mapping between words having the same number to discover the hidden meaning of texts (http://en.wikipedia.org/wiki/Gematria, http://essenes.net/gemcal.htm). <br>\n",
    "* Write a function gematria() that sums the numerical values of the letters of a word, according to the letter values in letter_vals: <br>\n",
    "* Process a corpus (e.g. nltk.corpus.state_union) and for each document, count how many of its words have the number 666. <br>\n",
    "* Write a function decode() to process a text, randomly replacing words with their Gematria equivalents, in order to discover the \"hidden meaning\" of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_vals = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':80, 'g':3, 'h':8,\n",
    "'i':10, 'j':10, 'k':20, 'l':30, 'm':40, 'n':50, 'o':70, 'p':80, 'q':100,\n",
    "'r':200, 's':300, 't':400, 'u':6, 'v':6, 'w':800, 'x':60, 'y':10, 'z':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gematria(word):\n",
    "    word=word.lower() # assuming both lower case and upper case letters have same numeric value\n",
    "    return sum(letter_vals[l] for l in word if l in list(letter_vals.keys()) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gematria('NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1945-Truman.txt 2\n",
      "1946-Truman.txt 13\n",
      "1947-Truman.txt 0\n",
      "1948-Truman.txt 2\n",
      "1949-Truman.txt 2\n",
      "1950-Truman.txt 1\n",
      "1951-Truman.txt 0\n",
      "1953-Eisenhower.txt 1\n",
      "1954-Eisenhower.txt 6\n",
      "1955-Eisenhower.txt 3\n",
      "1956-Eisenhower.txt 1\n",
      "1957-Eisenhower.txt 2\n",
      "1958-Eisenhower.txt 5\n",
      "1959-Eisenhower.txt 1\n",
      "1960-Eisenhower.txt 5\n",
      "1961-Kennedy.txt 0\n",
      "1962-Kennedy.txt 11\n",
      "1963-Johnson.txt 0\n",
      "1963-Kennedy.txt 5\n",
      "1964-Johnson.txt 1\n",
      "1965-Johnson-1.txt 0\n",
      "1965-Johnson-2.txt 0\n",
      "1966-Johnson.txt 0\n",
      "1967-Johnson.txt 2\n",
      "1968-Johnson.txt 3\n",
      "1969-Johnson.txt 0\n",
      "1970-Nixon.txt 0\n",
      "1971-Nixon.txt 1\n",
      "1972-Nixon.txt 0\n",
      "1973-Nixon.txt 1\n",
      "1974-Nixon.txt 0\n",
      "1975-Ford.txt 0\n",
      "1976-Ford.txt 3\n",
      "1977-Ford.txt 0\n",
      "1978-Carter.txt 1\n",
      "1979-Carter.txt 2\n",
      "1980-Carter.txt 0\n",
      "1981-Reagan.txt 4\n",
      "1982-Reagan.txt 0\n",
      "1983-Reagan.txt 2\n",
      "1984-Reagan.txt 1\n",
      "1985-Reagan.txt 1\n",
      "1986-Reagan.txt 1\n",
      "1987-Reagan.txt 1\n",
      "1988-Reagan.txt 2\n",
      "1989-Bush.txt 1\n",
      "1990-Bush.txt 2\n",
      "1991-Bush-1.txt 0\n",
      "1991-Bush-2.txt 0\n",
      "1992-Bush.txt 3\n",
      "1993-Clinton.txt 1\n",
      "1994-Clinton.txt 2\n",
      "1995-Clinton.txt 1\n",
      "1996-Clinton.txt 2\n",
      "1997-Clinton.txt 1\n",
      "1998-Clinton.txt 4\n",
      "1999-Clinton.txt 1\n",
      "2000-Clinton.txt 3\n",
      "2001-GWBush-1.txt 1\n",
      "2001-GWBush-2.txt 0\n",
      "2002-GWBush.txt 0\n",
      "2003-GWBush.txt 3\n",
      "2004-GWBush.txt 2\n",
      "2005-GWBush.txt 2\n",
      "2006-GWBush.txt 0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import state_union\n",
    "for f in state_union.fileids():\n",
    "    words=[w.lower() for w in state_union.words(f) if w.isalpha()];\n",
    "    values=nltk.FreqDist([gematria(w) for w in words]);\n",
    "    print(f,values[666]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n",
      "{'accorded', 'merely', 'equipped', 'free', 'virginia', 'reviving'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def decode(text):\n",
    "    num = random.randint(1, 1000)\n",
    "    return num, set([w.lower() for w in text if w.isalpha() and gematria(w.lower()) == num])\n",
    "\n",
    "result = decode(text4)\n",
    "print(result[0])\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 17\n",
    "Write a function shorten(text, n) to process a text, omitting the n most frequently occurring words of the text. How readable is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(text,n):\n",
    "    text=[w.lower() for w in text if w.isalpha()]\n",
    "    freq=nltk.FreqDist(text);\n",
    "    freq_words=[x[0] for x in freq.most_common(n)];\n",
    "    return [w for w in text if w not in freq_words];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moby', 'dick', 'herman', 'melville', 'etymology', 'supplied', 'late', 'consumptive', 'usher', 'grammar', 'school', 'pale', 'usher', 'threadbare', 'coat', 'heart', 'body', 'brain', 'see', 'ever', 'dusting', 'old', 'lexicons', 'grammars', 'queer', 'handkerchief', 'mockingly', 'embellished', 'gay', 'flags', 'known', 'nations', 'world', 'loved', 'dust', 'old', 'grammars', 'somehow', 'mildly', 'reminded', 'mortality', 'while', 'take', 'hand', 'school', 'others', 'teach', 'them', 'name', 'fish']\n"
     ]
    }
   ],
   "source": [
    "print(shorten(text1,50)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moby', 'dick', 'by', 'herman', 'melville', 'etymology', 'supplied', 'by', 'a', 'late', 'consumptive', 'usher', 'to', 'a', 'grammar', 'school', 'the', 'pale', 'usher', 'threadbare', 'in', 'coat', 'heart', 'body', 'and', 'brain', 'i', 'see', 'him', 'now', 'he', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and', 'grammars', 'with', 'a', 'queer', 'handkerchief', 'mockingly', 'embellished', 'with', 'all', 'the', 'gay', 'flags']\n"
     ]
    }
   ],
   "source": [
    "print([w.lower() for w in text1 if w.isalpha()][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top n most common words in any text will be mostly function words and the text without function words looks meaningless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 18\n",
    "Write code to print out an index for a lexicon, allowing someone to look up words according to their meanings (or pronunciations; whatever properties are contained in lexical entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fish', 'whale']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getWords(prop, value):\n",
    "    lexicon = [('fish', 'water animal', 'fish'), ('house', 'building', 'haus'), ('whale', 'water animal', 'wejl')]\n",
    "    if prop == 'meaning':\n",
    "        return [w for (w, m, p) in lexicon if m == value]\n",
    "    if prop == 'pronunciation':\n",
    "        return [w for (w, m, p) in lexicon if p == value]\n",
    "    \n",
    "getWords('meaning', 'water animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['house']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWords('pronunciation', 'haus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 19\n",
    "Write a list comprehension that sorts a list of WordNet synsets for proximity to a given synset. For example, given the synsets minke_whale.n.01, orca.n.01, novel.n.01, and tortoise.n.01, sort them according to their shortest_path_distance() from right_whale.n.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "synsets=[wn.synset('minke_whale.n.01'),wn.synset('orca.n.01'),wn.synset('novel.n.01'),wn.synset('tortoise.n.01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=sorted([s.shortest_path_distance(wn.synset('right_whale.n.01')) for s in synsets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('lesser_rorqual.n.01'),\n",
       " Synset('killer_whale.n.01'),\n",
       " Synset('novel.n.01'),\n",
       " Synset('tortoise.n.01')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in synsets for i in range(len(d)) if s.shortest_path_distance(wn.synset('right_whale.n.01'))==d[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 20\n",
    "Write a function that takes a list of words (containing duplicates) and returns a list of words (with no duplicates) sorted by decreasing frequency. E.g. if the input list contained 10 instances of the word table and 9 instances of the word chair, then table would appear before chair in the output list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortList(words):\n",
    "    words=nltk.FreqDist(words);\n",
    "    return [w[0] for w in words.most_common()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z', 'a']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortList(['a','z','a','z','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'z', '']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortList(['a','z','a',''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 21\n",
    "Write a function that takes a text and a vocabulary as its arguments and returns the set of words that appear in the text but not in the vocabulary. Both arguments can be represented as lists of strings. Can you do this in a single line, using set.difference()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDifference(text,vocabulary):\n",
    "    return {w for w in text if w not in vocabulary};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c', 'd'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setDifference(['a','b','b','c','c','d'],['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c', 'd'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set.difference({'a','b','b','c','c','d'},{'a','b'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 22\n",
    "Import the itemgetter() function from the operator module in Python's standard library (i.e. from operator import itemgetter). Create a list words containing several words. Now try calling: sorted(words, key=itemgetter(1)), and sorted(words, key=itemgetter(-1)). Explain what itemgetter() is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['a','b','c','d','e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class itemgetter in module operator:\n",
      "\n",
      "class itemgetter(builtins.object)\n",
      " |  itemgetter(item, ...) --> itemgetter object\n",
      " |  \n",
      " |  Return a callable object that fetches the given item(s) from its operand.\n",
      " |  After f = itemgetter(2), the call f(r) returns r[2].\n",
      " |  After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, /, *args, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Return state information for pickling\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(itemgetter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-7aa0be381d75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "sorted(words, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words, key=itemgetter(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words, key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "itemgetter returns the element from the specified position in an interable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 2), ('b', 1)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=[('a',2),('b',1)]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 2), ('b', 1)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 1), ('a', 2)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t,key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 23\n",
    "Write a recursive function lookup(trie, key) that looks up a key in a trie, and returns the value it finds. Extend the function to return a word when it is uniquely determined by its prefix (e.g. vanguard is the only word that starts with vang-, so lookup(trie, 'vang') should return the same thing as lookup(trie, 'vanguard'))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "insert(trie, 'vanguard', 'office')\n",
    "trie = dict(trie)               # for nicer printing\n",
    "trie['c']['h']['a']['t']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': {'h': {'a': {'i': {'r': {'value': 'flesh'}},\n",
      "                   't': {'value': 'cat'}},\n",
      "             'i': {'c': {'value': 'stylish'},\n",
      "                   'e': {'n': {'value': 'dog'}}}}},\n",
      " 'v': {'a': {'n': {'g': {'u': {'a': {'r': {'d': {'value': 'office'}}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(trie, key):\n",
    "    result=trie;\n",
    "    try:\n",
    "        key=list(key);\n",
    "        for i in range(len(key)):\n",
    "            result=result[key[i]];\n",
    "        if len(result)==1:\n",
    "            key=list(result.keys());\n",
    "            result=lookup(result,key);    \n",
    "        return result;\n",
    "    except:\n",
    "        print('value not found');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(trie, 'chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flesh'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(trie, 'chair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stylish'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(trie, 'chic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': {'n': {'value': 'dog'}}, 'c': {'value': 'stylish'}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(trie, 'chi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'office'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(trie, 'vanguard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'office'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup(trie, 'vang')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 24\n",
    "Read up on \"keyword linkage\" (chapter 5 of (Scott & Tribble, 2006)). Extract keywords from NLTK's Shakespeare Corpus and using the NetworkX package, plot keyword linkage networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Tragedy', 'of', 'Macbeth', 'Dramatis', 'Personae', 'DUNCAN', ',', 'king', 'of', 'Scotland', '.', 'MALCOLM', 'DONALBAIN', 'his', 'sons', '.', 'MACBETH', 'BANQUO', 'generals', 'of', 'the', 'king', \"'\", 's', 'army', '.', 'MACDUFF', 'LENNOX', 'ROSS', 'MENTEITH', 'ANGUS', 'CAITHNESS', 'noblemen', 'of', 'Scotland', '.', 'FLEANCE', ',', 'son', 'to', 'Banquo', '.', 'SIWARD', ',', 'Earl', 'of', 'Northumberland', ',', 'general', 'of', 'the', 'English', 'forces', '.', 'YOUNG', 'SIWARD', ',', 'his', 'son', '.', 'SEYTON', ',', 'an', 'officer', 'attending', 'on', 'Macbeth', '.', 'Boy', ',', 'son', 'to', 'Macduff', '.', 'An', 'English', 'Doctor', '.', 'A', 'Scotch', 'Doctor', '.', 'A', 'Soldier', '.', 'A', 'Porter', '.', 'An', 'Old', 'Man', '.', 'LADY', 'MACBETH', 'LADY', 'MACDUFF', 'Gentlewoman', 'attending', 'on']\n"
     ]
    }
   ],
   "source": [
    "words=shakespeare.words('macbeth.xml')\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 25\n",
    "Read about string edit distance and the Levenshtein Algorithm. Try the implementation provided in nltk.edit_distance(). In what way is this using dynamic programming? Does it use the bottom-up or top-down approach? [See also http://norvig.com/spell-correct.html]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance('INTENTION','EXECUTION',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is dynamic programming because it is an mathematical optimization of the edits by storing the intermediate edit results and selecting the minimum cost depending on the position. It uses bottom up approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 26\n",
    "The Catalan numbers arise in many applications of combinatorial mathematics, including the counting of parse trees (6). The series can be defined as follows: C0 = 1, and Cn+1 = 0..n (CiCn-i).\n",
    "\n",
    "* Write a recursive function to compute nth Catalan number Cn. <br>\n",
    "* Now write another function that does this computation using dynamic programming. <br>\n",
    "* Use the timeit module to compare the performance of these functions as n increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalan(number):\n",
    "    result=0;\n",
    "    if number in [0,1]:\n",
    "        return 1;\n",
    "    else:\n",
    "        for i in range(number):\n",
    "            result+=catalan(i)*catalan(number-1-i);\n",
    "        return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 2 42 1430\n"
     ]
    }
   ],
   "source": [
    "print(catalan(0),catalan(1),catalan(2),catalan(5),catalan(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalan_dynamic(n,lookup={0:1}):\n",
    "    if n in lookup:\n",
    "        return lookup[n];\n",
    "    else:\n",
    "        result=0;\n",
    "        for i in range(n):\n",
    "            result+=catalan_dynamic(i)*catalan_dynamic(n-1-i);\n",
    "        lookup[n]=result;\n",
    "        return lookup[n];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 2 42 1430\n"
     ]
    }
   ],
   "source": [
    "print(catalan_dynamic(0),catalan_dynamic(1),catalan_dynamic(2),catalan_dynamic(5),catalan_dynamic(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0671757749999955\n"
     ]
    }
   ],
   "source": [
    "from timeit import Timer\n",
    "t=Timer(lambda: catalan(10))\n",
    "print(t.timeit(number=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0051999996439918e-05\n"
     ]
    }
   ],
   "source": [
    "t=Timer(lambda: catalan_dynamic(10))\n",
    "print(t.timeit(number=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 27\n",
    "Reproduce some of the results of (Zhao & Zobel, 2007) concerning authorship identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link not working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 28\n",
    "Study gender-specific lexical choice, and see if you can reproduce some of the results of http://www.clintoneast.com/articles/words.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link not working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 29\n",
    "Write a recursive function that pretty prints a trie in alphabetically sorted order, e.g.: <br>\n",
    "\n",
    "chair: 'flesh'<br>\n",
    "---t: 'cat'<br>\n",
    "--ic: 'stylish'<br>\n",
    "---en: 'dog' <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_trie(trie, line=''):\n",
    "    if 'value' in trie:\n",
    "        print(line + ': \\'' + trie['value'] + '\\'');\n",
    "        return\n",
    "    for index, key in enumerate(sorted(trie.keys())):\n",
    "        if (index == 0):\n",
    "            pprint_trie(trie[key], line + key)\n",
    "        else:\n",
    "            pprint_trie(trie[key], ('-' * len(line)) + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair: 'flesh'\n",
      "---t: 'cat'\n",
      "--ic: 'stylish'\n",
      "---en: 'dog'\n",
      "vanguard: 'office'\n"
     ]
    }
   ],
   "source": [
    "pprint_trie(trie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 30\n",
    "With the help of the trie data structure, write a recursive function that processes text, locating the uniqueness point in each word, and discarding the remainder of each word. How much compression does this give? How readable is the resulting text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.17097144870496\n",
      "[ Mob Dic by Herm Melv 1851 ] ETY . ( Suppl by a Late Consu Ush to a Gramm School ) The pale Ush -- threadb in coat , heart , body , and brain ; I see him now . He was ever dusti his old lexicons and gramm , with a queer handk , mockingl embellishe with all the gay flags of all the known nations of the world . He loved to dust his old gramm ; it someh mildl reminde him of his mortality . \" While you take in hand to school others , and to teach them by what name a whale - fish is to be called in our tongue leaving out , through ignoranc , the letter H , which almo alone maket the significat of the word , you deliver that which is not true .\" -- HAC \" WHALE . ... Sw . and Dan . HVAL . This animal is named from roundn or rolling ; for in Dan . HVALT is arched or vaulte .\" -- WE ' S DIC \" WHALE . ... It is more immediatel from the Dut . and Ger . WALLEN ;\n"
     ]
    }
   ],
   "source": [
    "def lookup_unique(key, trie, unique='', buffer_unique=''):\n",
    "    if len(key) == 0:\n",
    "        if len(buffer_unique) > 0:\n",
    "            return buffer_unique\n",
    "        else:  \n",
    "            return unique\n",
    "    if len(trie[key[0]]) == 1:\n",
    "        if len(buffer_unique) > 0:\n",
    "            new_buffer_unique = buffer_unique\n",
    "        else:\n",
    "            new_buffer_unique = unique + key[0]\n",
    "        return lookup_unique(key[1:], trie[key[0]], unique + key[0], new_buffer_unique)\n",
    "    return lookup_unique(key[1:], trie[key[0]], unique + key[0])\n",
    "        \n",
    "\n",
    "def compress(text):          \n",
    "    trie = nltk.defaultdict(dict)\n",
    "    for word in text:\n",
    "        insert(trie, word, word)\n",
    "    return [lookup_unique(w, trie) for w in text]\n",
    "\n",
    "compressed = compress(text1)\n",
    "print((100.0/len(''.join(text1))) * len(''.join(compressed)))\n",
    "print(' '.join(compressed[:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 31\n",
    "Obtain some raw text, in the form of a single, long string. Use Python's textwrap module to break it up into multiple lines. Now write code to add extra spaces between words, in order to justify the output. Each line must have the same width, and spaces must be approximately evenly distributed across each line. No line can begin or end with a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=gutenberg.raw(fileids='austen-emma.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw=textwrap.wrap(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def justify(wrapped_text):\n",
    "    line_length = max(len(line) for line in wrapped_text)\n",
    "    for line in wrapped_text:\n",
    "        words = line.split()\n",
    "        num_chars = sum(len(word) for word in words)\n",
    "        num_spaces = line_length - num_chars\n",
    "        num_slots = len(words) - 1\n",
    "        fixed_spaces = int(num_spaces / num_slots)\n",
    "        spaces = 0\n",
    "        for index, word in enumerate(words[:-1]):\n",
    "            word += ' ' * fixed_spaces\n",
    "            spaces += fixed_spaces\n",
    "            words[index] = word\n",
    "            \n",
    "        while num_spaces - spaces > 0:\n",
    "            remainder = (num_spaces - spaces) % num_slots\n",
    "            chunk_size = int(len(words) / (remainder + 1))\n",
    "            chunk = 0\n",
    "            for index, word in enumerate(words[:-1]):\n",
    "                if remainder and chunk == chunk_size:\n",
    "                    word += ' '\n",
    "                    spaces += 1\n",
    "                    chunk = 0\n",
    "                else:    \n",
    "                    chunk += 1\n",
    "                words[index] = word\n",
    "            \n",
    "        print(''.join(words));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by  Jane  Austen  1816] VOLUME    I CHAPTER  I  Emma  Woodhouse,\n",
      "handsome,  clever,  and  rich,  with  a  comfortable  home  and  happy\n",
      "disposition, seemed to unite some of  the best blessings of existence;\n",
      "and had lived nearly twenty-one years in the world with very little to\n",
      "distress or vex her.  She was the youngest  of the two daughters  of a\n",
      "most affectionate, indulgent  father; and had,  in consequence of  her\n",
      "sister's marriage,  been mistress   of his  house from   a very  early\n",
      "period. Her mother had died too long ago  for her to have more than an\n",
      "indistinct remembrance  of  her  caresses; and    her place  had  been\n",
      "supplied by an  excellent woman as   governess, who had  fallen little\n",
      "short of a mother in affection. Sixteen  years had Miss Taylor been in\n",
      "Mr. Woodhouse's family, less as  a governess than a friend,  very fond\n",
      "of both daughters,  but particularly of   Emma. Between _them_  it was\n",
      "more the intimacy of  sisters. Even before  Miss  Taylor had ceased to\n",
      "hold the nominal office of  governess, the mildness of her  temper had\n",
      "hardly allowed  her  to  impose any    restraint; and  the  shadow  of\n",
      "authority being now long passed away, they had been living together as\n",
      "friend and friend very mutually attached, and Emma doing just what she\n",
      "liked; highly esteeming Miss  Taylor's judgment, but directed  chiefly\n",
      "by her  own. The  real evils,  indeed,  of  Emma's situation  were the\n",
      "power of having  rather too much  her  own way,  and a disposition  to\n",
      "think a little too well of herself; these were the disadvantages which\n",
      "threatened alloy to her  many enjoyments. The danger,  however, was at\n",
      "present so  unperceived, that   they did  not  by   any means  rank as\n",
      "misfortunes with her. Sorrow came--a gentle  sorrow--but not at all in\n",
      "the shape of any disagreeable  consciousness.--Miss Taylor married. It\n",
      "was Miss  Taylor's loss  which  first  brought grief.  It was   on the\n",
      "wedding-day of this  beloved friend that   Emma first sat  in mournful\n",
      "thought of any  continuance. The wedding   over, and the  bride-people\n",
      "gone, her  father and  herself were  left  to  dine together,  with no\n"
     ]
    }
   ],
   "source": [
    "justify(raw[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 32\n",
    "Develop a simple extractive summarization tool, that prints the sentences of a document which contain the highest total word frequency. Use FreqDist() to count word frequencies, and use sum to sum the frequencies of the words in each sentence. Rank the sentences according to their score. Finally, print the n highest-scoring sentences in document order. Carefully review the design of your program, especially your approach to this double sorting. Make sure the program is written as clearly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeText(text,n):\n",
    "    sents=nltk.sent_tokenize(text);\n",
    "    freq=[np.sum(list(nltk.FreqDist([w.lower() for w in sent]).values())) for sent in sents];\n",
    "    result=zip(sents,freq);\n",
    "    result=sorted(result,key=itemgetter(1),reverse=True);\n",
    "    print(*result[:n],sep='\\n');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emma by Jane Austen 1816 VOLUME I CHAPTER I Emma Woodhouse handsome clever and rich with a comfortable home and happy disposition seemed to unite some'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "raw=gutenberg.raw(fileids='austen-emma.txt');\n",
    "emma=' '.join(re.findall(r'\\w+\\.*',raw))\n",
    "emma[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('All that were good would be withdrawn and if to these losses the loss of Donwell were to be added what would remain of cheerful or of rational society within their reach Mr. Knightley to be no longer coming there for his evening comfort No longer walking in at all hours as if ever willing to change his own home for their s How was it to be endured And if he were to be lost to them for Harriet s sake if he were to be thought of hereafter as finding in Harriet s society all that he wanted if Harriet were to be the chosen the first the dearest the friend the wife to whom he looked for all the best blessings of existence what could be increasing Emma s wretchedness but the reflection never far distant from her mind that it had been all her own work When it came to such a pitch as this she was not able to refrain from a start or a heavy sigh or even from walking about the room for a few seconds and the only source whence any thing like consolation or composure could be drawn was in the resolution of her own better conduct and the hope that however inferior in spirit and gaiety might be the following and every future winter of her life to the past it would yet find her more rational more acquainted with herself and leave her less to regret when it were gone.', 1272)\n",
      "('She did not do any of it in the same way that she used I could see she was altered but however she seemed to _try_ to be very friendly and we shook hands and stood talking some time but I know no more what I said I was in such a tremble I remember she said she was sorry we never met now which I thought almost too kind Dear Miss Woodhouse I was absolutely miserable By that time it was beginning to hold up and I was determined that nothing should stop me from getting away and then only think I found he was coming up towards me too slowly you know and as if he did not quite know what to do and so he came and spoke and I answered and I stood for a minute feeling dreadfully you know one can t tell how and then I took courage and said it did not rain and I must go and so off I set and I had not got three yards from the door when he came after me only to say if I was going to Hartfield he thought I had much better go round by Mr. Cole s stables for I should find the near way quite floated by this rain.', 1010)\n"
     ]
    }
   ],
   "source": [
    "summarizeText(emma,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 33\n",
    " Read the following article on semantic orientation of adjectives. Use the NetworkX package to visualize a network of adjectives with edges to indicate same vs different semantic orientation. http://www.aclweb.org/anthology/P97-1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 34\n",
    " Design an algorithm to find the \"statistically improbable phrases\" of a document collection. http://www.amazon.com/gp/search-inside/sipshelp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 35\n",
    "Write a program to implement a brute-force algorithm for discovering word squares, a kind of n  n crossword in which the entry in the nth row is the same as the entry in the nth column. For discussion, see http://itre.cis.upenn.edu/~myl/languagelog/archives/002679.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['AREA', 'BALL', 'DEAR', 'LADY', 'LEAD', 'YARD']\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
